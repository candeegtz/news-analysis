{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ef5594-63dc-4ec7-9042-9ff2b95bf8a7",
   "metadata": {},
   "source": [
    "# Trabajo de Inteligencia artificial\n",
    " ## Análisis de noticias\n",
    "\n",
    " Realizado por:\n",
    " - Marta Aguilar Morcillo\n",
    " - Candela Jazmín Gutiérrez González\n",
    "\n",
    "Fecha: 30/05/2025\n",
    "\n",
    "Convocatoria de junio.\n",
    "\n",
    " ## 1. Lectura de datos\n",
    "\n",
    " Se comenzará con la lectura del corpus. Para ello, será necesaria la importación de las siguientes librerías:\n",
    " - **nltk:** \n",
    " - **punkt_tab:** para la tokenización de las palabras de los documentos.\n",
    " - **contractions:**\n",
    " - **sklearn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "664d7227-c596-4ba9-9265-2ba17abe1b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from nltk) (4.63.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "\n",
    "from nltk import download\n",
    "\n",
    "download('punkt_tab')                           # Tokenización\n",
    "nltk.download('averaged_perceptron_tagger')     # POS tagging\n",
    "nltk.download('averaged_perceptron_tagger_eng') # POS tagging\n",
    "nltk.download('wordnet')                        # WordNet lemmatizer\n",
    "nltk.download('omw-1.4')                        # WordNet multilingüe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a763f51b-d254-49b1-9642-c4ef91d2e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.data import path\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "\n",
    "path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c81921b-6b6f-4e41-b7d2-ba1e3685fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\usuario\\miniconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87eb78f2-614e-4ccb-b4de-9ed2ae89abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import re\n",
    "from bs4 import MarkupResemblesLocatorWarning\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0600f1f9-ea7b-4279-b084-e340b41f83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8504cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4734533-b325-41d9-afcc-bde22a4c36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "590d2b1f-c1bd-47f5-84e9-35b82ba8e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_vacias_ingles = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1465605",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f0d9972-08dd-4181-9d8c-124eed854eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimina_html(contenido):\n",
    "    return BeautifulSoup(contenido).get_text()\n",
    "\n",
    "def elimina_no_alfanumerico(contenido):\n",
    "    return [re.sub(r'[^\\w]', '', palabra)\n",
    "            for palabra in contenido\n",
    "            if re.search(r'\\w', palabra)]\n",
    "\n",
    "def expandir_constracciones(contenido):\n",
    "    return contractions.fix(contenido)\n",
    "\n",
    "def pasar_a_minuscula(contenido):\n",
    "    return contenido.lower()\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', ' ', texto)  # Reemplaza todo lo que no es letra o espacio con espacio\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto\n",
    "\n",
    "def elimina_palabras_vacias(contenido):\n",
    "    return [palabra for palabra in contenido if palabra not in palabras_vacias_ingles]\n",
    "\n",
    "def lematizador(contenido):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tags = pos_tag(contenido)\n",
    "\n",
    "    resultado = []\n",
    "    for palabra, tag in pos_tags:\n",
    "        if tag.startswith('VB'):  # Verbos\n",
    "            resultado.append(lemmatizer.lemmatize(palabra, pos='v'))  # infinitivo\n",
    "        else:  # Sustantivos y el resto tal como están\n",
    "            resultado.append(palabra)\n",
    "\n",
    "    return resultado\n",
    "\n",
    "def extraer_noun_chunks(tokens):\n",
    "    resultados = []\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    \n",
    "    noun_chunks = [chunk.text.lower().strip() for chunk in doc.noun_chunks if len(chunk.text.split()) <= 3]\n",
    "    noun_chunks_set = set(noun_chunks)\n",
    "\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        composed2 = \" \".join(tokens[i:i+2]).lower()\n",
    "        composed3 = \" \".join(tokens[i:i+3]).lower()\n",
    "\n",
    "        if composed3 in noun_chunks_set:\n",
    "            i += 3  \n",
    "        elif composed2 in noun_chunks_set:\n",
    "            i += 2 \n",
    "        else:\n",
    "            resultados.append(tokens[i].lower())  \n",
    "            i += 1\n",
    "\n",
    "    return resultados + noun_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be069f95-8d51-4137-82e6-c94ce64d6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceso_contenido(texto):\n",
    "    texto = elimina_html(texto)\n",
    "    texto = expandir_constracciones(texto)\n",
    "    texto = pasar_a_minuscula(texto)\n",
    "    texto = limpiar_texto(texto)                # Limpiar antes de tokenizar\n",
    "    tokens = word_tokenize(texto)               \n",
    "    tokens = elimina_no_alfanumerico(tokens)    # Limpiar tokens individuales\n",
    "    tokens = elimina_palabras_vacias(tokens)\n",
    "    tokens = lematizador(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "801b520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_normalizada_corpus():\n",
    "    df = pd.read_csv(\"news_corpus.csv\", encoding=\"latin-1\", sep=\";\", quotechar='\"')\n",
    "    resultados = []\n",
    "\n",
    "    df = df.head(105)\n",
    "    for index, fila in df.iterrows():\n",
    "        autor = [fila.iloc[0]]\n",
    "        titulo = fila.iloc[1]\n",
    "        cuerpo = fila.iloc[2]   \n",
    "\n",
    "        titulo_proc = proceso_contenido(titulo)\n",
    "        cuerpo_proc = proceso_contenido(cuerpo)\n",
    "\n",
    "        # Unir las tres listas en una sola lista combinada\n",
    "        fila_combinada =  autor + titulo_proc + cuerpo_proc\n",
    "\n",
    "        contenido_final = extraer_noun_chunks(fila_combinada)\n",
    "        resultados.append(contenido_final)\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "913fc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_documento(documento):\n",
    "    documento_procesado = proceso_contenido(documento) \n",
    "    contenido_final = extraer_noun_chunks(documento_procesado)\n",
    "    return contenido_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ec45a71-397d-4b8b-b0e4-4425fa107c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los primeros 3 documentos procesados\n",
    "def prueba_primeros_3_documentos_procesados(corpus):\n",
    "    for i, documento in enumerate(corpus[:3]):\n",
    "        print(f\"Documento {i+1}:\")\n",
    "        print(\" - Palabras:\", documento)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6a7099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_term(term):\n",
    "    related = set()\n",
    "    for syn in wn.synsets(term):\n",
    "        for lemma in syn.lemmas():\n",
    "            word = lemma.name().replace('_', ' ').lower()\n",
    "            if word != term:\n",
    "                related.add(word)\n",
    "    return related\n",
    "\n",
    "def expand_corpus_with_synonyms(corpus):\n",
    "    expanded_corpus = []\n",
    "    for doc in corpus:\n",
    "        # Obtenemos diccionario de palabra:repeticiones\n",
    "        doc_counter = Counter(doc)\n",
    "        expanded_doc = []\n",
    "        for word, count in doc_counter.items():\n",
    "            # Añadimos la palabra original tantas veces como aparece\n",
    "            expanded_doc.extend([word] * count)\n",
    "            # Obtenemos sinónimos y también los añadimos con la misma frecuencia\n",
    "            synonyms = expand_term(word)\n",
    "            for syn in synonyms:\n",
    "                expanded_doc.extend([syn] * count)\n",
    "        expanded_corpus.append(expanded_doc)\n",
    "    return expanded_corpus\n",
    "\n",
    "def tfidf_por_documentos_con_sinonimos(corpus_normalizado):\n",
    "     # Convertimos el corpus a lista de strings\n",
    "    corpus_expandido = expand_corpus_with_synonyms(corpus_normalizado)\n",
    "    texts = [\" \".join(doc) for doc in corpus_expandido]\n",
    "\n",
    "    # Vectorizador TF-IDF (1 y 2-gramas)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(texts)  # Matriz TF-IDF sparse\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Retornamos la matriz y vocabulario (términos)\n",
    "    return X, terms, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c9f47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_del_documento(documento, vectorizer):\n",
    "    documento_normalizado = lectura_documento(documento)\n",
    "    # Convertir el documento (lista de tokens) a string\n",
    "    texto = \" \".join(documento_normalizado)\n",
    "    # Transformar usando el vectorizador ya entrenado\n",
    "    X_doc = vectorizer.transform([texto])  # devuelve matriz sparse 1xN\n",
    "    return X_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64071395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_tfdifs_primeros_3_documentos(lista_diccionarios_tfidfs):\n",
    "    for idx, d in enumerate(lista_diccionarios_tfidfs[:3]):\n",
    "        top_terms = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\n Documento {idx+1}:\")\n",
    "        print(\"      Palabras añadidas por TF-IDF:\")\n",
    "        for term, score in top_terms:\n",
    "            print(f\"      - {term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11698ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_por_documentos_sin_sinonimos(corpus_normalizado):\n",
    "    # Convertimos el corpus a lista de strings\n",
    "    texts = [\" \".join(doc) for doc in corpus_normalizado]\n",
    "\n",
    "    # Vectorizador TF-IDF (1 y 2-gramas)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(texts)  # Matriz TF-IDF sparse\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Retornamos la matriz y vocabulario (términos)\n",
    "    return X, terms, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18246050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_matriz_tfidf_desde_diccionarios(tfidf_dicts):\n",
    "    # Construir vocabulario extendido unificado (con o sin sinónimos)\n",
    "    vocabulario = sorted(set().union(*[set(d.keys()) for d in tfidf_dicts]))\n",
    "\n",
    "    matriz = []\n",
    "    for doc_dict in tfidf_dicts:\n",
    "        vector = [doc_dict.get(term, 0.0) for term in vocabulario]\n",
    "        matriz.append(vector)\n",
    "    \n",
    "    matriz_tfidf = np.array(matriz)\n",
    "    vectorizer = TfidfVectorizer(vocabulary=vocabulario)\n",
    "\n",
    "    return matriz_tfidf,vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "833b6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similitud_coseno(tfidf_corpus, tfidf_doc, umbral=0.0):\n",
    "    # Calcular similitud coseno entre documento y corpus\n",
    "    similitudes = cosine_similarity(tfidf_doc, tfidf_corpus).flatten()\n",
    "\n",
    "    # Filtrar documentos que superan el umbral\n",
    "    indices_filtrados = [i for i, sim in enumerate(similitudes) if sim > umbral]\n",
    "\n",
    "    # Ordenar índices por similitud descendente\n",
    "    indices_ordenados = sorted(indices_filtrados, key=lambda i: similitudes[i], reverse=True)\n",
    "\n",
    "    # Devolver lista de (indice, similitud)\n",
    "    return [(i, similitudes[i]) for i in indices_ordenados]\n",
    "\n",
    "def documentos_similares(lista_similitudes):\n",
    "    for idx, score in lista_similitudes:\n",
    "        print(f\"Documento {idx} tiene similitud: {score:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28824fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 1:\n",
      " - Palabras: ['diu', 'revoke', 'mandatory', 'rakshabandhan', 'offices', 'order', 'daman', 'wednesday', 'withdraw', 'circular', 'ask', 'tie', 'rakhis', 'male', 'colleagues', 'order', 'trigger', 'backlash', 'employees', 'rip', 'apart', 'social', 'media', 'union', 'territory', 'administration', 'force', 'retreat', 'within', 'circular', 'make', 'celebrate', 'decide', 'celebrate', 'festival', 'rakshabandhan', 'august', 'connection', 'offices', 'departments', 'shall', 'remain', 'collectively', 'suitable', 'time', 'wherein', 'shall', 'tie', 'rakhis', 'colleagues', 'order', 'issue', 'august', 'gurpreet', 'singh', 'deputy', 'secretary', 'personnel', 'say', 'ensure', 'one', 'skipped', 'office', 'attendance', 'report', 'send', 'government', 'next', 'one', 'mandate', 'celebration', 'rakshabandhan', 'leave', 'withdraw', 'mandate', 'daman', 'day', 'apart', 'circular', 'withdrawn', 'one', 'line', 'order', 'issue', 'late', 'evening', 'ut', 'department', 'personnel', 'administrative', 'reforms', 'involve', 'government', 'dictate', 'maintain', 'tell', 'earlier', 'day', 'refuse', 'identified', 'daman', 'former', 'gujarat', 'home', 'minister', 'praful', 'kodabhai', 'patel', 'direction', 'sources', 'say', 'rakshabandhan', 'celebration', 'bond', 'brothers', 'sisters', 'one', 'several', 'hindu', 'festivities', 'rituals', 'longer', 'confine', 'become', 'tools', 'push', 'politic', 'al', 'ideologies', 'year', 'bjp', 'storm', 'power', 'centre', 'rashtriya', 'rss', 'say', 'celebrate', 'widely', 'protect', 'hindu', 'culture', 'live', 'values', 'enshrine', 'rss', 'ideological', 'parent', 'ruling', 'bjp', 'last', 'year', 'modi', 'government', 'go', 'celebrate', 'festival', 'soldiers', 'year', 'cabinet', 'ministers', 'ask', 'go', 'chhavi tyagi daman', 'diu', 'diu administration', 'women staff', 'hours issue', 'compulsory staff', 'rakshabandhan workplace', 'open celebrate festival', 'lady staff', 'government', 'even two notifications', 'mandate', 'right issue', 'circular ridiculous sensitivities', 'government', 'tie rakhi', 'professionalism workplace official', 'hindustan times', 'notice issue', 'diu administrator', 'rituals', 'private family affairs', 'tools', 'swayamsevak sangh', 'chief mohan bhagwat', 'festival national significance', 'women ministers', 'government', 'border areas', 'constituencies festival']\n",
      "\n",
      "Documento 2:\n",
      " - Palabras: ['slams', 'user', 'troll', 'divorcing', 'rich', 'man', 'special', 'numbers', 'bollywood', 'actor', 'malaika', 'arora', 'khan', 'manage', 'make', 'debut', 'hindi', 'film', 'industry', 'blockbuster', 'debut', 'opposite', 'shah', 'rukh', 'khan', 'chaiyya', 'chaiyya', 'still', 'remember', 'song', 'however', 'trolls', 'woman', 'first', 'matters', 'right', 'divorce', 'rich', 'man', 'share', 'follower', 'decide', 'read', 'wear', 'go', 'gym', 'salon', 'little', 'know', 'munni', 'badnam', 'star', 'would', 'reply', 'take', 'look', 'interaction', 'super', 'excite', 'affiliated', 'khanna', 'jewellers', 'khannajewellerskj', 'brand', 'ambassador', 'craft', 'perfection', 'stun', 'statement', 'jewellery', 'must', 'khannajewellers', 'maksquad', 'hair', 'hairbypriyanka', 'stylist', 'manekaharisinghani', 'manager', 'ektakauroberoi', 'mua', 'subbu', 'photographer', 'prasdnaik', 'post', 'share', 'malaika', 'arora', 'khan', 'malaikaarorakhanofficial', 'aug', 'pdt', 'malaika', 'decide', 'prove', 'matter', 'woman', 'successful', 'attack', 'moment', 'decides', 'decide', 'apart', 'successful', 'woman', 'live', 'life', 'terms', 'malaika', 'literally', 'play', 'roles', 'traditionally', 'prescribe', 'woman', 'marry', 'raise', 'always', 'around', 'khandan', 'get', 'divorce', 'alimony', 'taunt', 'thrown', 'details', 'alimony', 'know', 'malaika', 'husband', 'arbaaz', 'khan', 'perhaps', 'family', 'couple', 'handle', 'divorce', 'need', 'alimony', 'buy', 'clothes', 'go', 'vacations', 'enjoy', 'life', 'anything', 'successful', 'happen', 'arbaaz', 'malaika', 'personal', 'concern', 'claim', 'malaika', 'marry', 'hold', 'water', 'agree', 'please', 'get', 'course', 'playlist', 'follow', 'daisy mowke malaika', 'tv appearances', 'carve identity actor', 'dil se', 'song', 'woman', 'wednesday malaika arora', 'gorgeous picture instagram', 'follower', 'troll use alumni', 'alimony money', 'short clothes', 'perfect comeback', 'interaction', 'every jewellery lover', 'reply entire conversation', 'step bounds society', 'roles', 'woman', 'quite early son', 'khandan', 'divorce', 'utmost dignity', 'vouch fact', 'alimony', 'clothes', 'short choice', 'vacations', 'life', 'anything', 'ex husband', 'malaika', 'divorce arbaaz money', 'water', 'feminism others', 'popular songs', 'htshowbiz']\n",
      "\n",
      "Documento 3:\n",
      " - Palabras: ['arshiya chopra', 'virgin', 'correct', 'unmarried', 'igims', 'form', 'indira', 'gandhi', 'institute', 'medical', 'sciences', 'igims', 'patna', 'amend', 'marital', 'declaration', 'form', 'thursday', 'replace', 'word', 'virgin', 'unmarried', 'controversy', 'super', 'specialty', 'medical', 'institute', 'state', 'capital', 'require', 'declare', 'bachelors', 'widowers', 'virgins', 'igims', 'say', 'institute', 'director', 'dr', 'nr', 'biswas', 'hold', 'meeting', 'thursday', 'morning', 'directing', 'word', 'virgin', 'marital', 'declaration', 'form', 'immediately', 'replace', 'biswas', 'return', 'four', 'day', 'leave', 'absence', 'earlier', 'bihar', 'health', 'minister', 'mangal', 'pandey', 'end', 'redefine', 'mean', 'virginity', 'attempts', 'justify', 'awkward', 'phrase', 'question', 'form', 'follow', 'tell', 'nothing', 'wrong', 'use', 'word', 'virgin', 'simply', 'meant', 'kanya', 'kunwari', 'mean', 'unmarried', 'girl', 'pandey', 'join', 'cabinet', 'three', 'days', 'ago', 'sources', 'say', 'also', 'take', 'ask', 'even', 'ask', 'question', 'introduce', 'first', 'place', 'response', 'management', 'autonomous', 'super', 'specialty', 'health', 'facility', 'clarify', 'wednesday', 'adherence', 'central', 'civil', 'services', 'rules', 'follow', 'india', 'institute', 'medical', 'sciences', 'new', 'delhi', 'previous', 'version', 'marital', 'declaration', 'form', 'purportedly', 'ask', 'virgins', 'ht', 'photo', 'marital', 'declaration', 'form', 'existence', 'since', 'blame', 'faux', 'pas', 'poor', 'translation', 'part', 'individuals', 'draft', 'form', 'nothing', 'seek', 'know', 'employees', 'marital', 'status', 'dues', 'could', 'settle', 'basis', 'declaration', 'event', 'death', 'service', 'say', 'new recruits', 'bachelors', 'virgins', 'medical superintendent', 'dr manish mandal', 'unmarried dr', 'public furore document', 'wednesday minister', 'news channels', 'nothing', 'sources', 'chief minister office', 'cognizance issue', 'copy form', 'question', 'inception institute officials', 'document word', 'virgin mention', 'nothing', 'virginity employee', 'dr mandal']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prueba de lectura \n",
    "resultados = lectura_normalizada_corpus()\n",
    "prueba_primeros_3_documentos_procesados(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6aa91041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras: ['union', 'minister', 'transport', 'ship', 'nitin', 'gadkari', 'demand', 'maharashtra', 'government', 'provide', 'special', 'facilities', 'detain', 'emergency', 'maintenance', 'internal', 'security', 'act', 'misa', 'misa', 'detainees', 'sunday', 'hold', 'sangh', 'nagpur', 'meeting', 'gadkari', 'mahal', 'residence', 'group', 'lead', 'sangh', 'sacchidanand', 'upasane', 'national', 'secretary', 'komal', 'chief', 'jayprakash', 'pande', 'insist', 'detainees', 'treat', 'give', 'facilities', 'available', 'freedom', 'fighter', 'country', 'incidentally', 'misa', 'detainees', 'rss', 'activists', 'supporters', 'group', 'submit', 'memorandum', 'gadkari', 'brief', 'facilities', 'recognition', 'extend', 'like', 'mp', 'states', 'detainees', 'consider', 'par', 'give', 'pensions', 'facilities', 'government', 'rajasthan', 'recently', 'form', 'available', 'misa', 'defence', 'india', 'rules', 'committee', 'report', 'state', 'soon', 'claim', 'group', 'also', 'point', 'madhya', 'pradesh', 'misa', 'detainees', 'dub', 'draw', 'monthly', 'honorarium', 'rs', 'gadkari', 'tell', 'group', 'already', 'speak', 'chief', 'minister', 'devendra', 'fadnavis', 'state', 'finance', 'minister', 'sudhir', 'munganttiwar', 'regard', 'positive', 'issue', 'congress', 'meanwhile', 'accuse', 'bjp', 'lead', 'government', 'try', 'give', 'facilities', 'move', 'totally', 'political', 'one', 'say', 'former', 'union', 'minister', 'vilas', 'muttemwar', 'muttemwar', 'warn', 'party', 'would', 'launch', 'accept', 'compare', 'convention banner satyagrahi', 'vice president', 'chheda maharashtra unit', 'detainees', 'freedom fighters', 'facilities', 'detainees', 'detainees states', 'bihar chhattisgarh claim', 'detainees', 'par', 'freedom fighters', 'committee study facilities', 'group', 'democracy warrior', 'congress', 'bjp', 'government', 'facilities', 'parivar members', 'party', 'statewide agitation government', 'group demand', 'sangh parivar members', 'freedom fighters']\n"
     ]
    }
   ],
   "source": [
    "documento = \"Union minister for transport and shipping Nitin Gadkari has demanded that the Maharashtra government provide special facilities to those detained during the Emergency under the Maintenance of Internal Security Act (MISA). The MISA detainees on?Sunday held a convention under the banner of Satyagrahi Sangh in Nagpur after meeting Gadkari at his Mahal residence. The group, led by the Sangh?s vice-president Sacchidanand Upasane, national secretary Komal Chheda and Maharashtra unit chief Jayprakash Pande insisted that the detainees be treated as freedom fighters and be given all facilities available to a freedom fighter in the country. Incidentally, most of the MISA detainees are RSS activists or its supporters.The group submitted a memorandum to Gadkari, briefing him about the facilities and recognition extended to detainees in states like UP, MP, Bihar and Chhattisgarh. They claimed that in these states, the detainees are considered at par with the freedom fighters and given pensions and other facilities. The government in Rajasthan recently formed a committee to study facilities available to MISA and Defence of India Rules 1971 detainees in other states. The committee will its report to the state soon, they claimed. The group also pointed out that in Madhya Pradesh, MISA detainees, dubbed as ?Democracy Warrior? draw a monthly honorarium of Rs 25,000. Gadkari told the group he had already spoken to chief minister Devendra Fadnavis and the state finance minister, Sudhir Munganttiwar, in this regard. ?Both were positive on the issue.? The Congress, meanwhile, has accused the BJP-led government of trying to give such facilities to its Sangh Parivar members. ?The move is totally a political one,? says former Union minister Vilas Muttemwar. Muttemwar warned his party would launch a statewide agitation if government accepted the group?s demand.?How can these Sangh Parivar members be compared with freedom fighters??\"\n",
    "lectura = lectura_documento(documento)\n",
    "print(\" - Palabras:\", lectura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da2841c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 19 tiene similitud: 0.1114\n",
      "Documento 71 tiene similitud: 0.0938\n",
      "Documento 82 tiene similitud: 0.0837\n",
      "Documento 4 tiene similitud: 0.0817\n",
      "Documento 75 tiene similitud: 0.0812\n",
      "Documento 103 tiene similitud: 0.0758\n",
      "Documento 0 tiene similitud: 0.0679\n",
      "Documento 42 tiene similitud: 0.0672\n",
      "Documento 104 tiene similitud: 0.0658\n",
      "Documento 94 tiene similitud: 0.0648\n",
      "Documento 39 tiene similitud: 0.0594\n",
      "Documento 44 tiene similitud: 0.0592\n",
      "Documento 15 tiene similitud: 0.0550\n",
      "Documento 18 tiene similitud: 0.0482\n",
      "Documento 36 tiene similitud: 0.0476\n",
      "Documento 14 tiene similitud: 0.0452\n",
      "Documento 88 tiene similitud: 0.0447\n",
      "Documento 83 tiene similitud: 0.0444\n",
      "Documento 52 tiene similitud: 0.0444\n",
      "Documento 2 tiene similitud: 0.0413\n",
      "Documento 63 tiene similitud: 0.0372\n",
      "Documento 9 tiene similitud: 0.0369\n",
      "Documento 22 tiene similitud: 0.0364\n",
      "Documento 33 tiene similitud: 0.0361\n",
      "Documento 99 tiene similitud: 0.0361\n",
      "Documento 95 tiene similitud: 0.0340\n",
      "Documento 62 tiene similitud: 0.0324\n",
      "Documento 76 tiene similitud: 0.0323\n",
      "Documento 7 tiene similitud: 0.0306\n",
      "Documento 64 tiene similitud: 0.0305\n",
      "Documento 53 tiene similitud: 0.0292\n",
      "Documento 43 tiene similitud: 0.0277\n",
      "Documento 29 tiene similitud: 0.0277\n",
      "Documento 25 tiene similitud: 0.0277\n",
      "Documento 11 tiene similitud: 0.0261\n",
      "Documento 35 tiene similitud: 0.0256\n",
      "Documento 57 tiene similitud: 0.0252\n",
      "Documento 100 tiene similitud: 0.0250\n",
      "Documento 45 tiene similitud: 0.0247\n",
      "Documento 68 tiene similitud: 0.0243\n",
      "Documento 30 tiene similitud: 0.0239\n",
      "Documento 61 tiene similitud: 0.0229\n",
      "Documento 77 tiene similitud: 0.0220\n",
      "Documento 67 tiene similitud: 0.0210\n",
      "Documento 96 tiene similitud: 0.0208\n",
      "Documento 32 tiene similitud: 0.0206\n",
      "Documento 50 tiene similitud: 0.0206\n",
      "Documento 5 tiene similitud: 0.0204\n",
      "Documento 13 tiene similitud: 0.0203\n",
      "Documento 66 tiene similitud: 0.0201\n",
      "Documento 102 tiene similitud: 0.0198\n",
      "Documento 80 tiene similitud: 0.0197\n",
      "Documento 84 tiene similitud: 0.0194\n",
      "Documento 8 tiene similitud: 0.0191\n",
      "Documento 21 tiene similitud: 0.0191\n",
      "Documento 93 tiene similitud: 0.0187\n",
      "Documento 16 tiene similitud: 0.0187\n",
      "Documento 86 tiene similitud: 0.0181\n",
      "Documento 12 tiene similitud: 0.0181\n",
      "Documento 98 tiene similitud: 0.0178\n",
      "Documento 40 tiene similitud: 0.0168\n",
      "Documento 101 tiene similitud: 0.0163\n",
      "Documento 49 tiene similitud: 0.0163\n",
      "Documento 26 tiene similitud: 0.0160\n",
      "Documento 78 tiene similitud: 0.0153\n",
      "Documento 72 tiene similitud: 0.0152\n",
      "Documento 3 tiene similitud: 0.0147\n",
      "Documento 28 tiene similitud: 0.0145\n",
      "Documento 91 tiene similitud: 0.0140\n",
      "Documento 31 tiene similitud: 0.0139\n",
      "Documento 79 tiene similitud: 0.0138\n",
      "Documento 37 tiene similitud: 0.0134\n",
      "Documento 38 tiene similitud: 0.0131\n",
      "Documento 47 tiene similitud: 0.0130\n",
      "Documento 85 tiene similitud: 0.0129\n",
      "Documento 90 tiene similitud: 0.0127\n",
      "Documento 87 tiene similitud: 0.0122\n",
      "Documento 20 tiene similitud: 0.0118\n",
      "Documento 56 tiene similitud: 0.0114\n",
      "Documento 41 tiene similitud: 0.0109\n",
      "Documento 24 tiene similitud: 0.0105\n",
      "Documento 6 tiene similitud: 0.0100\n",
      "Documento 46 tiene similitud: 0.0095\n",
      "Documento 73 tiene similitud: 0.0094\n",
      "Documento 69 tiene similitud: 0.0094\n",
      "Documento 59 tiene similitud: 0.0086\n",
      "Documento 51 tiene similitud: 0.0086\n",
      "Documento 74 tiene similitud: 0.0083\n",
      "Documento 89 tiene similitud: 0.0083\n",
      "Documento 54 tiene similitud: 0.0082\n",
      "Documento 58 tiene similitud: 0.0076\n",
      "Documento 34 tiene similitud: 0.0075\n",
      "Documento 81 tiene similitud: 0.0073\n",
      "Documento 60 tiene similitud: 0.0069\n",
      "Documento 92 tiene similitud: 0.0065\n",
      "Documento 1 tiene similitud: 0.0051\n",
      "Documento 97 tiene similitud: 0.0051\n",
      "Documento 48 tiene similitud: 0.0047\n",
      "Documento 17 tiene similitud: 0.0043\n",
      "Documento 70 tiene similitud: 0.0042\n",
      "Documento 65 tiene similitud: 0.0042\n",
      "Documento 10 tiene similitud: 0.0039\n",
      "Documento 55 tiene similitud: 0.0025\n",
      "Documento 23 tiene similitud: 0.0023\n",
      "Documento 27 tiene similitud: 0.0021\n"
     ]
    }
   ],
   "source": [
    "# Prueba de similitud sin sinonimos\n",
    "documento = \"Union minister for transport and shipping Nitin Gadkari has demanded that the Maharashtra government provide special facilities to those detained during the Emergency under the Maintenance of Internal Security Act (MISA). The MISA detainees on?Sunday held a convention under the banner of Satyagrahi Sangh in Nagpur after meeting Gadkari at his Mahal residence. The group, led by the Sangh?s vice-president Sacchidanand Upasane, national secretary Komal Chheda and Maharashtra unit chief Jayprakash Pande insisted that the detainees be treated as freedom fighters and be given all facilities available to a freedom fighter in the country. Incidentally, most of the MISA detainees are RSS activists or its supporters.The group submitted a memorandum to Gadkari, briefing him about the facilities and recognition extended to detainees in states like UP, MP, Bihar and Chhattisgarh. They claimed that in these states, the detainees are considered at par with the freedom fighters and given pensions and other facilities. The government in Rajasthan recently formed a committee to study facilities available to MISA and Defence of India Rules 1971 detainees in other states. The committee will its report to the state soon, they claimed. The group also pointed out that in Madhya Pradesh, MISA detainees, dubbed as ?Democracy Warrior? draw a monthly honorarium of Rs 25,000. Gadkari told the group he had already spoken to chief minister Devendra Fadnavis and the state finance minister, Sudhir Munganttiwar, in this regard. ?Both were positive on the issue.? The Congress, meanwhile, has accused the BJP-led government of trying to give such facilities to its Sangh Parivar members. ?The move is totally a political one,? says former Union minister Vilas Muttemwar. Muttemwar warned his party would launch a statewide agitation if government accepted the group?s demand.?How can these Sangh Parivar members be compared with freedom fighters??\"\n",
    "corpus_normalizado = lectura_normalizada_corpus()\n",
    "tfidf_corpus_sin_sinonimos, terms, vectorizer = tfidf_por_documentos_sin_sinonimos(corpus_normalizado)\n",
    "tfidf_documento = tfidf_del_documento(documento, vectorizer)\n",
    "resultados_similitud = similitud_coseno(tfidf_corpus_sin_sinonimos, tfidf_documento)\n",
    "documentos_similares(resultados_similitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e3fd6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 82 tiene similitud: 0.1071\n",
      "Documento 71 tiene similitud: 0.0881\n",
      "Documento 103 tiene similitud: 0.0659\n",
      "Documento 39 tiene similitud: 0.0616\n",
      "Documento 99 tiene similitud: 0.0608\n",
      "Documento 44 tiene similitud: 0.0600\n",
      "Documento 42 tiene similitud: 0.0571\n",
      "Documento 15 tiene similitud: 0.0551\n",
      "Documento 0 tiene similitud: 0.0544\n",
      "Documento 75 tiene similitud: 0.0540\n",
      "Documento 36 tiene similitud: 0.0537\n",
      "Documento 19 tiene similitud: 0.0493\n",
      "Documento 104 tiene similitud: 0.0468\n",
      "Documento 94 tiene similitud: 0.0467\n",
      "Documento 14 tiene similitud: 0.0457\n",
      "Documento 9 tiene similitud: 0.0451\n",
      "Documento 4 tiene similitud: 0.0422\n",
      "Documento 88 tiene similitud: 0.0371\n",
      "Documento 43 tiene similitud: 0.0369\n",
      "Documento 61 tiene similitud: 0.0364\n",
      "Documento 76 tiene similitud: 0.0351\n",
      "Documento 96 tiene similitud: 0.0342\n",
      "Documento 83 tiene similitud: 0.0341\n",
      "Documento 95 tiene similitud: 0.0336\n",
      "Documento 25 tiene similitud: 0.0315\n",
      "Documento 52 tiene similitud: 0.0309\n",
      "Documento 33 tiene similitud: 0.0308\n",
      "Documento 53 tiene similitud: 0.0296\n",
      "Documento 68 tiene similitud: 0.0289\n",
      "Documento 5 tiene similitud: 0.0287\n",
      "Documento 16 tiene similitud: 0.0283\n",
      "Documento 45 tiene similitud: 0.0280\n",
      "Documento 26 tiene similitud: 0.0266\n",
      "Documento 35 tiene similitud: 0.0263\n",
      "Documento 7 tiene similitud: 0.0260\n",
      "Documento 40 tiene similitud: 0.0241\n",
      "Documento 67 tiene similitud: 0.0238\n",
      "Documento 11 tiene similitud: 0.0238\n",
      "Documento 18 tiene similitud: 0.0230\n",
      "Documento 57 tiene similitud: 0.0223\n",
      "Documento 13 tiene similitud: 0.0223\n",
      "Documento 64 tiene similitud: 0.0219\n",
      "Documento 2 tiene similitud: 0.0216\n",
      "Documento 21 tiene similitud: 0.0216\n",
      "Documento 62 tiene similitud: 0.0212\n",
      "Documento 22 tiene similitud: 0.0210\n",
      "Documento 72 tiene similitud: 0.0208\n",
      "Documento 70 tiene similitud: 0.0204\n",
      "Documento 87 tiene similitud: 0.0203\n",
      "Documento 32 tiene similitud: 0.0202\n",
      "Documento 86 tiene similitud: 0.0197\n",
      "Documento 90 tiene similitud: 0.0197\n",
      "Documento 29 tiene similitud: 0.0195\n",
      "Documento 101 tiene similitud: 0.0195\n",
      "Documento 77 tiene similitud: 0.0192\n",
      "Documento 3 tiene similitud: 0.0190\n",
      "Documento 41 tiene similitud: 0.0182\n",
      "Documento 66 tiene similitud: 0.0182\n",
      "Documento 93 tiene similitud: 0.0175\n",
      "Documento 80 tiene similitud: 0.0175\n",
      "Documento 37 tiene similitud: 0.0174\n",
      "Documento 56 tiene similitud: 0.0171\n",
      "Documento 92 tiene similitud: 0.0171\n",
      "Documento 38 tiene similitud: 0.0168\n",
      "Documento 85 tiene similitud: 0.0164\n",
      "Documento 98 tiene similitud: 0.0160\n",
      "Documento 60 tiene similitud: 0.0159\n",
      "Documento 100 tiene similitud: 0.0155\n",
      "Documento 78 tiene similitud: 0.0155\n",
      "Documento 30 tiene similitud: 0.0152\n",
      "Documento 8 tiene similitud: 0.0149\n",
      "Documento 69 tiene similitud: 0.0149\n",
      "Documento 59 tiene similitud: 0.0146\n",
      "Documento 58 tiene similitud: 0.0146\n",
      "Documento 79 tiene similitud: 0.0144\n",
      "Documento 51 tiene similitud: 0.0143\n",
      "Documento 91 tiene similitud: 0.0141\n",
      "Documento 10 tiene similitud: 0.0138\n",
      "Documento 49 tiene similitud: 0.0136\n",
      "Documento 54 tiene similitud: 0.0136\n",
      "Documento 48 tiene similitud: 0.0136\n",
      "Documento 1 tiene similitud: 0.0135\n",
      "Documento 84 tiene similitud: 0.0131\n",
      "Documento 63 tiene similitud: 0.0124\n",
      "Documento 24 tiene similitud: 0.0123\n",
      "Documento 74 tiene similitud: 0.0117\n",
      "Documento 81 tiene similitud: 0.0112\n",
      "Documento 50 tiene similitud: 0.0112\n",
      "Documento 102 tiene similitud: 0.0111\n",
      "Documento 89 tiene similitud: 0.0106\n",
      "Documento 12 tiene similitud: 0.0103\n",
      "Documento 46 tiene similitud: 0.0101\n",
      "Documento 23 tiene similitud: 0.0100\n",
      "Documento 20 tiene similitud: 0.0097\n",
      "Documento 65 tiene similitud: 0.0096\n",
      "Documento 6 tiene similitud: 0.0094\n",
      "Documento 31 tiene similitud: 0.0093\n",
      "Documento 34 tiene similitud: 0.0092\n",
      "Documento 27 tiene similitud: 0.0088\n",
      "Documento 55 tiene similitud: 0.0087\n",
      "Documento 17 tiene similitud: 0.0083\n",
      "Documento 47 tiene similitud: 0.0074\n",
      "Documento 73 tiene similitud: 0.0067\n",
      "Documento 28 tiene similitud: 0.0055\n",
      "Documento 97 tiene similitud: 0.0052\n"
     ]
    }
   ],
   "source": [
    "# Prueba de tfidfs con sinonimos\n",
    "documento = \"Union minister for transport and shipping Nitin Gadkari has demanded that the Maharashtra government provide special facilities to those detained during the Emergency under the Maintenance of Internal Security Act (MISA). The MISA detainees on?Sunday held a convention under the banner of Satyagrahi Sangh in Nagpur after meeting Gadkari at his Mahal residence. The group, led by the Sangh?s vice-president Sacchidanand Upasane, national secretary Komal Chheda and Maharashtra unit chief Jayprakash Pande insisted that the detainees be treated as freedom fighters and be given all facilities available to a freedom fighter in the country. Incidentally, most of the MISA detainees are RSS activists or its supporters.The group submitted a memorandum to Gadkari, briefing him about the facilities and recognition extended to detainees in states like UP, MP, Bihar and Chhattisgarh. They claimed that in these states, the detainees are considered at par with the freedom fighters and given pensions and other facilities. The government in Rajasthan recently formed a committee to study facilities available to MISA and Defence of India Rules 1971 detainees in other states. The committee will its report to the state soon, they claimed. The group also pointed out that in Madhya Pradesh, MISA detainees, dubbed as ?Democracy Warrior? draw a monthly honorarium of Rs 25,000. Gadkari told the group he had already spoken to chief minister Devendra Fadnavis and the state finance minister, Sudhir Munganttiwar, in this regard. ?Both were positive on the issue.? The Congress, meanwhile, has accused the BJP-led government of trying to give such facilities to its Sangh Parivar members. ?The move is totally a political one,? says former Union minister Vilas Muttemwar. Muttemwar warned his party would launch a statewide agitation if government accepted the group?s demand.?How can these Sangh Parivar members be compared with freedom fighters??\"\n",
    "corpus_normalizado = lectura_normalizada_corpus()\n",
    "tfidf_corpus_con_sinonimos, terms, vectorizer = tfidf_por_documentos_con_sinonimos(corpus_normalizado)\n",
    "tfidf_documento = tfidf_del_documento(documento, vectorizer)\n",
    "resultados_similitud = similitud_coseno(tfidf_corpus_con_sinonimos, tfidf_documento)\n",
    "documentos_similares(resultados_similitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21bef957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m lista_diccionarios_tfidf_sinonimos \u001b[38;5;241m=\u001b[39m tfidf_por_documentos_con_sinonimos(resultados)\n\u001b[0;32m      4\u001b[0m tfidf_corpus_con_sinonimos, vectorizer \u001b[38;5;241m=\u001b[39m construir_matriz_tfidf_desde_diccionarios(lista_diccionarios_tfidf_sinonimos)\n\u001b[1;32m----> 5\u001b[0m tfidf_documento \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_del_documento\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocumento\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m resultados_similitud \u001b[38;5;241m=\u001b[39m similitud_coseno(tfidf_corpus_con_sinonimos, tfidf_documento)\n\u001b[0;32m      7\u001b[0m documentos_similares(resultados_similitud)\n",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36mtfidf_del_documento\u001b[1;34m(documento, vectorizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m texto \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(documento_normalizado)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Transformar usando el vectorizador ya entrenado\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_doc \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtexto\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# devuelve matriz sparse 1xN\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_doc\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2148\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents):\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m \n\u001b[0;32m   2135\u001b[0m \u001b[38;5;124;03m    Uses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;124;03m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2148\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe TF-IDF vectorizer is not fitted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2150\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtransform(raw_documents)\n\u001b[0;32m   2151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36897756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
